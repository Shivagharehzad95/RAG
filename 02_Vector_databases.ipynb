{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Vector Databases and Similarity Search\n",
    "\n",
    "## 2.1 Overview of Vector Databases\n",
    "\n",
    "### What are Vector Databases?\n",
    "- **Vector Databases** are designed to store and search high-dimensional vectors, which represent data points in a multi-dimensional space.\n",
    "- These vectors are often generated by machine learning models (e.g., embeddings from NLP models) and are used to capture the semantic meaning of text, images, or other data types.\n",
    "\n",
    "### Why Use Vector Databases?\n",
    "- **Efficiency**: Vector databases enable fast similarity searches, crucial for tasks like finding similar documents, images, or even generating recommendations.\n",
    "- **Scalability**: They can handle large datasets with millions or even billions of vectors, making them suitable for real-world applications.\n",
    "\n",
    "### Popular Vector Databases\n",
    "- **Pinecone**: A managed vector database service that scales automatically and provides real-time search capabilities.\n",
    "- **Milvus**: An open-source vector database optimized for high-performance similarity search, particularly in large datasets.\n",
    "- **Chroma**: An open-source vector database designed for AI applications, emphasizing fast and efficient similarity searches.\n",
    "- **Weaviate**: An open-source vector database with support for various data types and integrations, including semantic search capabilities.\n",
    "- **FAISS (Facebook AI Similarity Search)**: A popular library developed by Facebook AI for efficient similarity search and clustering of dense vectors.\n",
    "- **Elasticsearch**: A distributed search engine that has added support for vector search, making it suitable for integrating with other structured and unstructured data searches.\n",
    "- **Qdrant**: An open-source vector search engine and database that provides high-performance, real-time vector search capabilities with a focus on efficient nearest neighbor search.\n",
    "\n",
    "<br>\n",
    "<img src=\"images/vectordb.png\" width=\"700\">\n",
    "\n",
    "### Comparing vector databases\n",
    "Examples of things that you should keep in mind when considering a vector database:\n",
    "- **Deployment options**)\n",
    "- **Scalability**\n",
    "- **Performance and Benchmarking**\n",
    "- **Data Management**\n",
    "- **Algorithms for Vector similarity search**\n",
    "- **Integration and API**\n",
    "- **Security**\n",
    "- **Community and ecosystem**\n",
    "- **Pricing**\n",
    "- **Additional features**\n",
    "\n",
    "\n",
    "[Vector database comparison](https://zackproser.com/blog/vector-databases-compared)\n",
    "\n",
    "\n",
    "## 2.3 Usual Metrics in Vector Databases\n",
    "\n",
    "### Common Similarity Metrics\n",
    "- **L2 (Euclidean) Distance**: Measures the straight-line distance between two points in vector space. Commonly used in many vector databases.\n",
    "- **Cosine Similarity**: Measures the cosine of the angle between two vectors. Useful when you care about the direction rather than the magnitude.\n",
    "- **Inner Product**: Measures the dot product of two vectors, often used in neural networks.\n",
    "\n",
    "## 2.4 Vector Indexing Algorithms\n",
    "\n",
    "### Importance of Indexing\n",
    "- Indexing improves the efficiency of similarity searches, especially when dealing with large datasets.\n",
    "\n",
    "### Common Indexing Algorithms\n",
    "- **IVF (Inverted File Index)**: Splits the vector space into clusters, each with its own index.\n",
    "- **HNSW (Hierarchical Navigable Small World)**: A graph-based indexing method that allows for efficient approximate nearest neighbor searches.\n",
    "- **PQ (Product Quantization)**: Compresses vectors into smaller codes, reducing memory usage.\n",
    "\n",
    "### Activity:\n",
    "Experiment with different indexing algorithms in FAISS or another vector database. Compare the search speeds and accuracy for different algorithms.\n",
    "\"\"\"))\n",
    "\n",
    "# Python cell: Example of IVF Indexing in FAISS\n",
    "# Set up an IVF index\n",
    "nlist = 100  # number of clusters\n",
    "quantizer = faiss.IndexFlatL2(d)  # the quantizer to build the IVF index\n",
    "index_ivf = faiss.IndexIVFFlat(quantizer, d, nlist)\n",
    "\n",
    "# Train the index\n",
    "index_ivf.train(xb)\n",
    "\n",
    "# Add vectors to the index\n",
    "index_ivf.add(xb)\n",
    "\n",
    "# Perform the search using IVF\n",
    "index_ivf.nprobe = 10  # number of clusters to search in\n",
    "D_ivf, I_ivf = index_ivf.search(xq, k)\n",
    "\n",
    "print(\"Indices of nearest neighbors (IVF):\", I_ivf)\n",
    "print(\"Distances to nearest neighbors (IVF):\", D_ivf)\n",
    "\n",
    "# Markdown cell: Summary and Next Steps\n",
    "display(Markdown(\"\"\"\n",
    "## Summary and Next Steps\n",
    "\n",
    "### What We Covered:\n",
    "- **Vector Databases**: An overview of what they are and why they're useful.\n",
    "- **FAISS Setup**: How to create and index vectors, and perform similarity searches.\n",
    "- **Similarity Metrics**: Explored common metrics like L2 distance and cosine similarity.\n",
    "- **Indexing Algorithms**: Discussed and experimented with different indexing methods.\n",
    "\n",
    "### Next Steps:\n",
    "- Continue exploring other vector databases like Milvus or Pinecone.\n",
    "- Try indexing larger datasets and measure the impact on search performance.\n",
    "- Experiment with pre- and post-filtering techniques to refine search results.\n",
    "\n",
    "In the next part of the workshop, we'll dive into using LLMs for generating responses based on retrieved data.\n",
    "\"\"\"))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
