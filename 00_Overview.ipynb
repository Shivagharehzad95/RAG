{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RAG overview\n",
    "- Vector databases and similarity search\n",
    "  - Overview different vector databases\n",
    "  - Usual metrics\n",
    "  - Vector Indexing Algorithms\n",
    "  - Pre and Post-Filtering\n",
    "- LLMs for generative response\n",
    "  - Ollama, Langchain\n",
    "- Putting everything together\n",
    "- Benchmarking RAG Systems\n",
    "- Improving RAG Performance\n",
    "  - Updating Chunk Size\n",
    "  - Re-Ranking\n",
    "  - Query transformations\n",
    "  - LORA and QLORA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Vector databases and similarity search\n",
    "### Overview different vector databases\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Usual metrics\n",
    "- Euclidean distance\n",
    "- Cosine similarity\n",
    "- Dot Product similarity\n",
    "\n",
    "### Vector Indexing Algorithms\n",
    "ANN Algorithms\n",
    "\n",
    "- Spatial Partitioning (also known as cluster-based indexing or clustering indexes)\n",
    "- Graph-based indexing (e.g. HNSW)\n",
    "- Hash-based indexing (e.g., locality-sensitive hashing)\n",
    "\n",
    "\n",
    "- [Resource 1](https://gagan-mehta.medium.com/understanding-vector-dbs-indexing-algorithms-ce187dca69c2)\n",
    "- [HNSW](https://www.datastax.com/de/guides/hierarchical-navigable-small-worlds)\n",
    "\n",
    "### Pre and Post-Filtering\n",
    "\n",
    "- [Resource 1](https://www.pinecone.io/learn/vector-database/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## LLMs for generative response\n",
    "  - [Ollama](https://ollama.com/) \n",
    "  - [LlamaIndex](https://www.llamaindex.ai/)\n",
    "  - [Langchain](https://www.langchain.com/)\n",
    "\n",
    "![LlamaIndex vs LangChain](images/Llamaindex-Langchain.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting everything together\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking RAG Systems\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving RAG Performance\n",
    "  - Updating Chunk Size, Chunk Overlap and Chunk number\n",
    "  - Re-Ranking:\n",
    "    - Re-Ranking with FlagEmbeddingReranker: To retrieve the relevant chunks, we can use an open-source Re-Ranking model from Hugging Face, called the bge-ranker-base model.\n",
    "    - Re-Ranking with RankGPTRerank: This time, we can rely on an LLM as a Re-Ranker. Here, we use the module RankGPT, which leverages the GPT modelâ€™s capabilities to rank documents within the RAG system\n",
    "  - Query transformations\n",
    "    - HyDE: Where we transform user queries and their hypothetical answers into embeddings to retrieve closely matching documents in the vector space.\n",
    "    - Multi-Step Query Transformations: Where we divide a complex user query into sequential subquestions for effective processing.\n",
    "  - LORA and QLORA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- [RAG Resources]( https://github.com/mrdbourke/rag-resources)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
